{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nobody knows anything\n",
    "#                  -Kai\n",
    "#\n",
    "# github.com/kaibrooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version 2.0.0\n",
      "Keras version 2.2.4-tf\n",
      "Numpy version 1.17.4\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers import Dropout # dropout crew 4 lyf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt # fancy plots\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime # so we know how much time we've wasted\n",
    "\n",
    "print('TensorFlow version', tf.__version__)\n",
    "print('Keras version', keras.__version__)\n",
    "#print('SciPy version', scipy.__version__)\n",
    "print('Numpy version', np.__version__) \n",
    "#print('Pillow version', PIL.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doin thangs\n",
    "epochs = 60 #60\n",
    "epochOutput = False\n",
    "temperature = [0.2, 0.5, 1.0, 1.2]\n",
    "earlyStop = True\n",
    "\n",
    "\n",
    "np.seterr(divide='ignore') # ignore divide by zero warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data/alice.txt\n",
      "corpus length : 144343\n",
      "unique chars  : 44\n",
      "total patterns: 48101\n",
      "\n",
      "corpus would be better at 1M words\n",
      "\n",
      "Vectorizing...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "## get text file and parse it\n",
    "\n",
    "#path = get_file( # use this for http request\n",
    "#    'afile.txt',\n",
    "#    origin='http://omega.lul/afile.txt')\n",
    "\n",
    "# look for a .txt file in /data\n",
    "source = 'alice'\n",
    "\n",
    "path = os.path.join('data', source + '.txt')\n",
    "\n",
    "print('Loaded',path)\n",
    "\n",
    "# print sweet ~data~ about the file\n",
    "with open(path, encoding='utf-8', errors='ignore') as f: # errors=ignore strips non utf-8 chars\n",
    "    text = f.read().lower()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print('corpus length :', len(text))\n",
    "print('unique chars  :', len(chars))\n",
    "print('total patterns:', len(sentences))\n",
    "print('') # empty line\n",
    "\n",
    "if len(text) < 100000:\n",
    "    print('corpus should be at least 100K words')\n",
    "    print('') # empty line\n",
    "elif len(text) < 1000000:\n",
    "    print('corpus would be better at 1M words')\n",
    "    print('') # empty line\n",
    "\n",
    "    \n",
    "print('Vectorizing...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "## model\n",
    "# this has NO TEST DATASET\n",
    "\n",
    "print('Building model...')\n",
    "#model = Sequential()\n",
    "#model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "#model.add(Dense(len(chars), activation='softmax'))\n",
    "#optimizer = RMSprop(learning_rate=0.01)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer) # metrics=['accuracy']\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2019-12-13_17-50-08 UTC\n",
      "Epoch 1/60\n",
      "48101/48101 [==============================] - 49s 1ms/step - loss: 2.5313\n",
      "Epoch 2/60\n",
      "48101/48101 [==============================] - 49s 1ms/step - loss: 1.8769\n",
      "Epoch 3/60\n",
      "48101/48101 [==============================] - 49s 1ms/step - loss: 1.6771\n",
      "Epoch 4/60\n",
      "48101/48101 [==============================] - 49s 1ms/step - loss: 1.5572\n",
      "Epoch 5/60\n",
      "48101/48101 [==============================] - 49s 1ms/step - loss: 1.4739\n",
      "Epoch 6/60\n",
      "48101/48101 [==============================] - 49s 1ms/step - loss: 1.4144\n",
      "Epoch 7/60\n",
      "48101/48101 [==============================] - 49s 1ms/step - loss: 1.3575\n",
      "Epoch 8/60\n",
      "48101/48101 [==============================] - 49s 1ms/step - loss: 1.3238\n",
      "Epoch 9/60\n",
      "48101/48101 [==============================] - 49s 1ms/step - loss: 1.2808\n",
      "Epoch 10/60\n",
      "48101/48101 [==============================] - 49s 1ms/step - loss: 1.2513\n",
      "Epoch 11/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.2219\n",
      "Epoch 12/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.2046\n",
      "Epoch 13/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.1771\n",
      "Epoch 14/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.1605\n",
      "Epoch 15/60\n",
      "48101/48101 [==============================] - 53s 1ms/step - loss: 1.1449\n",
      "Epoch 16/60\n",
      "48101/48101 [==============================] - 57s 1ms/step - loss: 1.1319\n",
      "Epoch 17/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.1142\n",
      "Epoch 18/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.0965\n",
      "Epoch 19/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.0948\n",
      "Epoch 20/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.0810\n",
      "Epoch 21/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.0712\n",
      "Epoch 22/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.0572\n",
      "Epoch 23/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.0439\n",
      "Epoch 24/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.0384\n",
      "Epoch 25/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.0296\n",
      "Epoch 26/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.0179\n",
      "Epoch 27/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 1.0048\n",
      "Epoch 28/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.9973\n",
      "Epoch 29/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.9840\n",
      "Epoch 30/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.9872\n",
      "Epoch 31/60\n",
      "48101/48101 [==============================] - 51s 1ms/step - loss: 0.9702\n",
      "Epoch 32/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.9684\n",
      "Epoch 33/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.9603\n",
      "Epoch 34/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.9534\n",
      "Epoch 35/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.9425\n",
      "Epoch 36/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.9372\n",
      "Epoch 37/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.9325\n",
      "Epoch 38/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.9177\n",
      "Epoch 39/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.9186\n",
      "Epoch 40/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.9017\n",
      "Epoch 41/60\n",
      "48101/48101 [==============================] - 51s 1ms/step - loss: 0.9060\n",
      "Epoch 42/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8968\n",
      "Epoch 43/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8900\n",
      "Epoch 44/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8870\n",
      "Epoch 45/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8777\n",
      "Epoch 46/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8657\n",
      "Epoch 47/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8578\n",
      "Epoch 48/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8590\n",
      "Epoch 49/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8542\n",
      "Epoch 50/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8439\n",
      "Epoch 51/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8412\n",
      "Epoch 52/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8403\n",
      "Epoch 53/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8352\n",
      "Epoch 54/60\n",
      "48101/48101 [==============================] - 51s 1ms/step - loss: 0.8345\n",
      "Epoch 55/60\n",
      "48101/48101 [==============================] - 51s 1ms/step - loss: 0.8182\n",
      "Epoch 56/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8122\n",
      "Epoch 57/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8147\n",
      "Epoch 58/60\n",
      "48101/48101 [==============================] - 50s 1ms/step - loss: 0.8140\n",
      "Epoch 59/60\n",
      "48101/48101 [==============================] - 52s 1ms/step - loss: 0.8065\n",
      "Epoch 60/60\n",
      "48101/48101 [==============================] - 51s 1ms/step - loss: 0.8069\n",
      "Finished training at 13-Dec-2019 18:40:23\n",
      "Model summary:\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 40, 128)           88576     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 44)                5676      \n",
      "=================================================================\n",
      "Total params: 225,836\n",
      "Trainable params: 225,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train me\n",
    "now = datetime.now()\n",
    "runDate = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "print(\"Starting training at\", runDate, 'UTC') # lets see how long this takes\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    if epochOutput:\n",
    "        # print text at each epoch\n",
    "        print()\n",
    "        print('**************************** Generating text after Epoch: %d ****************************' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "        for temperature in [temperature]:\n",
    "            print('--------------- temperature: ', temperature, '---------------')\n",
    "\n",
    "            generated = ''\n",
    "            sentence = text[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print('--------------- seed: <', sentence,'>')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(400):\n",
    "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = sample(preds, temperature)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                sentence = sentence[1:] + next_char\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "            print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "\n",
    "# early stopping\n",
    "# loss, accuracy\n",
    "\n",
    "if earlyStop:\n",
    "    #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "    #es = EarlyStopping(monitor='loss', mode='min', min_delta=1, baseline=0.1)\n",
    "    es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=round(epochs*1.1)) # stop early if no progress for 10% of max epochs\n",
    "\n",
    "\n",
    "mc1 = ModelCheckpoint('trained_models/best_model.h5', monitor='loss', mode='min', save_best_only=True)\n",
    "mc2 = ModelCheckpoint('trained_models/last_model.h5') # save model each run\n",
    "\n",
    "history = model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          callbacks=[print_callback, es, mc1, mc2]) # add back es!\n",
    "\n",
    "then = datetime.now()\n",
    "print(\"Finished training at\", then.strftime(\"%d-%b-%Y %H:%M:%S\")) # lets see how long this took\n",
    "\n",
    "print('Model summary:')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saved last model at /tf/notebooks/trained_models/alice_2019-12-13_17-50-08_trainedmodel_last.h5 \n",
      "Saved best model at /tf/notebooks/trained_models/alice_2019-12-13_17-50-08_trainedmodel_best.h5 \n",
      "Saved summary at /tf/notebooks/trained_models/alice_2019-12-13_17-50-08_modelsummary.txt\n",
      "Model is 2 MB\n"
     ]
    }
   ],
   "source": [
    "## save models and log\n",
    "\n",
    "# this is where you pay attention to where you mapped the Docker dir to your local dir at run\n",
    "save_dir = os.path.join(os.getcwd(), 'trained_models')\n",
    "\n",
    "if not os.path.isdir(save_dir): # make dir if it doesn't exist\n",
    "    os.makedirs(save_dir)    \n",
    "    print(save_dir, 'doesn\\'t exist, creating it')\n",
    "\n",
    "print('Saving...') # do this because saving the model takes 5+ seconds sometimes\n",
    "\n",
    "\n",
    "# name the files\n",
    "last_name =  source + '_' + runDate + '_trainedmodel_last.h5'\n",
    "summary_name = source + '_' + runDate + '_modelsummary.txt'\n",
    "best_name = source + '_' + runDate + '_trainedmodel_best.h5'\n",
    "\n",
    "\n",
    "# get the best model\n",
    "saved_model = load_model('trained_models/best_model.h5')\n",
    "\n",
    "# save best model\n",
    "model_path = os.path.join(save_dir, best_name)\n",
    "saved_model.save(model_path)\n",
    "\n",
    "# get the last model\n",
    "last_model = model\n",
    "\n",
    "# save last model\n",
    "model_path = os.path.join(save_dir, last_name)\n",
    "last_model.save(model_path)\n",
    "\n",
    "# save summary\n",
    "with open(os.path.join(save_dir, summary_name),'w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "\n",
    "\n",
    "print('Saved last model at %s ' % os.path.join(save_dir, last_name)) \n",
    "print('Saved best model at %s ' % os.path.join(save_dir, best_name)) \n",
    "print('Saved summary at %s' % os.path.join(save_dir, summary_name))   \n",
    "\n",
    "size = os.path.getsize(model_path) # note how big the model is because they're often huge\n",
    "print('Model is',round(size/1e+6),'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.8064774066152173\n"
     ]
    }
   ],
   "source": [
    "## plot training information\n",
    "# accuracy\n",
    "#plt.plot(history.history['accuracy']) # kx or similar Matlab commands for plotting\n",
    "#plt.plot(history.history['val_accuracy'])\n",
    "#plt.title('model accuracy')\n",
    "#plt.ylabel('accuracy')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'test'], loc='lower right')\n",
    "#plt.show()\n",
    "\n",
    "# loss\n",
    "loss_min = np.min(history.history['loss'])\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.scatter(loss_min, list(range(1, 200)), 'kx')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.savefig(source + '_' + runDate + '_loss.png')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Min:', str(loss_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded /tf/notebooks/trained_models/last_model.h5\n"
     ]
    }
   ],
   "source": [
    "## load a model for testing\n",
    "\n",
    "model_path = os.path.join(save_dir, 'last_model.h5') # external file\n",
    "#model_path = os.path.join(save_dir, last_name) # last\n",
    "#model_path = os.path.join(save_dir, best_name) # best\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "print('Loaded', model_path)\n",
    "\n",
    "#optimizer = RMSprop(learning_rate=0.01)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=optimizer) # metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** seed: < aning in them, after all. \"--saidi coul >\n",
      "\n",
      " aning in them, after all. \"--saidi could have casted outsing to see the right the gryphon; and the king was too executing in the cards.'\n",
      "\n",
      "'what made out that\n",
      "in that\n",
      "quite time,' said the cat. 'i don't be behand to sun--ono theme, and glad as she was get the white rabbit's hand of feet of meanver sight the time they would get to the ligst to her: it was quite forgotten in the\n",
      "crown in the time\n",
      "sort!'\n",
      "\n",
      "'the first witness changed it with\n"
     ]
    }
   ],
   "source": [
    "## set for the final output\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "sentence = text[start_index: start_index + maxlen]\n",
    "randomizeOut = False\n",
    "temperature = 0.5 # 0.5? depends on training length\n",
    "maxChars = 400 # 400 is same as above\n",
    "\n",
    "if randomizeOut:\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "\n",
    "seed = sentence.replace('\\n','')\n",
    "seed = seed.replace('\\t','')\n",
    "print('*** seed: <', seed ,'>')\n",
    "#sys.stdout.write(generated)\n",
    "\n",
    "print('\\n',seed, end = '')\n",
    "\n",
    "for i in range(maxChars):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
